{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMucp2TD1z/qbBD2PhVSMRC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15212ab9","executionInfo":{"status":"ok","timestamp":1767702483426,"user_tz":-330,"elapsed":2258,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"cc23c5cb-4dfd-499b-f6fb-82937c6873ed"},"source":["import pandas as pd\n","\n","df = pd.read_csv('SRN_dataset1.csv')\n","\n","# Print the total number of samples (rows)\n","print(f\"Total number of samples: {len(df)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of samples: 50000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80bde1af","executionInfo":{"status":"ok","timestamp":1767702492782,"user_tz":-330,"elapsed":66,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"0bd53d65-3f20-4a27-a296-98f451870458"},"source":["print(\"\\nDistribution of sentiment labels before conversion:\")\n","print(df['sentiment'].value_counts())\n","\n","# Convert sentiment labels to binary (1 for 'positive', 0 for 'negative')\n","df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n","\n","print(\"\\nDistribution of sentiment labels after conversion:\")\n","print(df['sentiment'].value_counts())\n","print(\"\\nFirst few rows with converted sentiment:\")\n","print(df.head())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Distribution of sentiment labels before conversion:\n","sentiment\n","positive    25000\n","negative    25000\n","Name: count, dtype: int64\n","\n","Distribution of sentiment labels after conversion:\n","sentiment\n","1    25000\n","0    25000\n","Name: count, dtype: int64\n","\n","First few rows with converted sentiment:\n","                                              review  sentiment\n","0  One of the other reviewers has mentioned that ...          1\n","1  A wonderful little production. <br /><br />The...          1\n","2  I thought this was a wonderful way to spend ti...          1\n","3  Basically there's a family where a little boy ...          0\n","4  Petter Mattei's \"Love in the Time of Money\" is...          1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"687d9ace","executionInfo":{"status":"ok","timestamp":1767701244403,"user_tz":-330,"elapsed":6147,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"ee1d7b7c-a89f-42ac-de2c-df699006d04e"},"source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download necessary NLTK data (if not already downloaded)\n","print(\"Downloading NLTK data (punkt, stopwords, wordnet). This may take a moment...\")\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","nltk.download('wordnet', quiet=True)\n","print(\"NLTK data download complete.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading NLTK data (punkt, stopwords, wordnet). This may take a moment...\n","NLTK data download complete.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef88bd88","executionInfo":{"status":"ok","timestamp":1767701265705,"user_tz":-330,"elapsed":59,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"092aa4ec-41d2-45a8-f0a6-d837a04ea01f"},"source":["def preprocess_text(text):\n","    # 1. Convert to lowercase\n","    text = text.lower()\n","\n","    # 2. Remove punctuation, special characters, and numbers\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","    # 3. Tokenize the text\n","    tokens = word_tokenize(text)\n","\n","    # 4. Get English stopwords\n","    stop_words = set(stopwords.words('english'))\n","\n","    # 5. Remove stopwords\n","    filtered_tokens = [word for word in tokens if word not in stop_words]\n","\n","    # 6. Initialize WordNetLemmatizer\n","    lemmatizer = WordNetLemmatizer()\n","\n","    # 7. Lemmatize each token\n","    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n","\n","    return lemmatized_tokens\n","\n","print(\"The 'preprocess_text' function has been defined.\")\n","# Example usage (optional, for verification)\n","# sample_text = \"This is a sample review, with some numbers 123 and punctuation! Isn't it great?\"\n","# preprocessed_sample = preprocess_text(sample_text)\n","# print(f\"Original: {sample_text}\")\n","# print(f\"Preprocessed: {preprocessed_sample}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The 'preprocess_text' function has been defined.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":773},"id":"1a86a531","executionInfo":{"status":"error","timestamp":1767701303075,"user_tz":-330,"elapsed":514,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"f88a5780-dfbb-40fd-9b27-f163c145cde1"},"source":["print(\"Applying preprocess_text function to 'review' column...\")\n","df['preprocessed_review'] = df['review'].apply(preprocess_text)\n","print(\"Preprocessing complete. First few preprocessed reviews:\")\n","print(df[['review', 'preprocessed_review']].head())\n","\n","# Import train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Define features (X) and target (y)\n","X = df['preprocessed_review']\n","y = df['sentiment']\n","\n","# Split the dataset into training (80%) and testing (20%) sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"\\nShape of X_train: {X_train.shape}\")\n","print(f\"Shape of X_test: {X_test.shape}\")\n","print(f\"Shape of y_train: {y_train.shape}\")\n","print(f\"Shape of y_test: {y_test.shape}\")\n","print(\"Data split into training and testing sets successfully.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Applying preprocess_text function to 'review' column...\n"]},{"output_type":"error","ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1106821775.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Applying preprocess_text function to 'review' column...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocessed_review'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing complete. First few preprocessed reviews:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'preprocessed_review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n","\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3193347409.py\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 3. Tokenize the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 4. Get English stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     return [\n\u001b[1;32m    144\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"]}]},{"cell_type":"markdown","metadata":{"id":"0353a447"},"source":["**Reasoning**:\n","The previous error indicated that the 'punkt_tab' resource was not found, which is a dependency for NLTK's `word_tokenize` function. I need to explicitly download 'punkt_tab' along with the other NLTK data to resolve this issue.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa7a0ad4","executionInfo":{"status":"ok","timestamp":1767701337583,"user_tz":-330,"elapsed":591,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"697387a0-6e6a-4d25-c043-2f7a3bb2d7fc"},"source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","# Download necessary NLTK data (if not already downloaded)\n","print(\"Downloading NLTK data (punkt, stopwords, wordnet, punkt_tab). This may take a moment...\")\n","nltk.download('punkt', quiet=True)\n","nltk.download('stopwords', quiet=True)\n","nltk.download('wordnet', quiet=True)\n","nltk.download('punkt_tab', quiet=True) # Added to fix the LookupError\n","print(\"NLTK data download complete.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading NLTK data (punkt, stopwords, wordnet, punkt_tab). This may take a moment...\n","NLTK data download complete.\n"]}]},{"cell_type":"markdown","metadata":{"id":"b5beaa11"},"source":["**Reasoning**:\n","Now that the necessary NLTK data, including 'punkt_tab', has been successfully downloaded, I will re-attempt to apply the `preprocess_text` function to the 'review' column and then split the dataset into training and testing sets as per the subtask instructions.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e50c42f3","executionInfo":{"status":"ok","timestamp":1767701369426,"user_tz":-330,"elapsed":4309,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"7af223eb-87bb-4a61-b511-97b433fb33ae"},"source":["print(\"Applying preprocess_text function to 'review' column...\")\n","df['preprocessed_review'] = df['review'].apply(preprocess_text)\n","print(\"Preprocessing complete. First few preprocessed reviews:\")\n","print(df[['review', 'preprocessed_review']].head())\n","\n","# Import train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Define features (X) and target (y)\n","X = df['preprocessed_review']\n","y = df['sentiment']\n","\n","# Split the dataset into training (80%) and testing (20%) sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(f\"\\nShape of X_train: {X_train.shape}\")\n","print(f\"Shape of X_test: {X_test.shape}\")\n","print(f\"Shape of y_train: {y_train.shape}\")\n","print(f\"Shape of y_test: {y_test.shape}\")\n","print(\"Data split into training and testing sets successfully.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Applying preprocess_text function to 'review' column...\n","Preprocessing complete. First few preprocessed reviews:\n","                                              review  \\\n","0  One of the other reviewers has mentioned that ...   \n","1  A wonderful little production. <br /><br />The...   \n","2  I thought this was a wonderful way to spend ti...   \n","3  Basically there's a family where a little boy ...   \n","4  Petter Mattei's \"Love in the Time of Money\" is...   \n","\n","                                 preprocessed_review  \n","0  [one, reviewer, mentioned, watching, oz, episo...  \n","1  [wonderful, little, production, br, br, filmin...  \n","2  [thought, wonderful, way, spend, time, hot, su...  \n","3  [basically, there, family, little, boy, jake, ...  \n","4  [petter, matteis, love, time, money, visually,...  \n","\n","Shape of X_train: (16,)\n","Shape of X_test: (4,)\n","Shape of y_train: (16,)\n","Shape of y_test: (4,)\n","Data split into training and testing sets successfully.\n"]}]},{"cell_type":"markdown","metadata":{"id":"6ac172d7"},"source":["## Manual Feature Extraction (Bag-of-Words)\n","\n","### Subtask:\n","Manually implement Bag-of-Words feature extraction by building a unique vocabulary from the training data and converting each review (both training and testing) into a word-frequency dictionary without using scikit-learn's vectorizers.\n"]},{"cell_type":"markdown","metadata":{"id":"bdef606d"},"source":["**Reasoning**:\n","I will initialize an empty set for the vocabulary, iterate through the training reviews to populate it, define a function to create word frequency dictionaries, and then apply this function to both training and testing sets to generate Bag-of-Words representations, finally printing the vocabulary size and samples from the transformed data.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12ec4941","executionInfo":{"status":"ok","timestamp":1767701404760,"user_tz":-330,"elapsed":12,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"37b27bfb-c10a-49e3-e836-f0376d23d23f"},"source":["print(\"Building vocabulary from training data...\")\n","vocabulary = set()\n","for review_tokens in X_train:\n","    vocabulary.update(review_tokens)\n","\n","print(f\"Vocabulary size: {len(vocabulary)}\")\n","\n","def create_word_frequency_dict(tokens, vocab):\n","    word_freq = {}\n","    for word in tokens:\n","        if word in vocab: # Only consider words present in the training vocabulary\n","            word_freq[word] = word_freq.get(word, 0) + 1\n","    return word_freq\n","\n","print(\"Converting training reviews to Bag-of-Words...\")\n","X_train_bow = [create_word_frequency_dict(review_tokens, vocabulary) for review_tokens in X_train]\n","\n","print(\"Converting testing reviews to Bag-of-Words...\")\n","X_test_bow = [create_word_frequency_dict(review_tokens, vocabulary) for review_tokens in X_test]\n","\n","print(\"\\nFirst 3 entries of X_train_bow:\")\n","for i, entry in enumerate(X_train_bow[:3]):\n","    print(f\"Review {i+1}: {entry}\")\n","\n","print(\"\\nFirst 3 entries of X_test_bow:\")\n","for i, entry in enumerate(X_test_bow[:3]):\n","    print(f\"Review {i+1}: {entry}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Building vocabulary from training data...\n","Vocabulary size: 762\n","Converting training reviews to Bag-of-Words...\n","Converting testing reviews to Bag-of-Words...\n","\n","First 3 entries of X_train_bow:\n","Review 1: {'encouraged': 1, 'positive': 1, 'comment': 1, 'film': 6, 'looking': 1, 'forward': 1, 'watching': 1, 'bad': 1, 'mistake': 1, 'ive': 1, 'seen': 1, 'truly': 1, 'one': 2, 'worst': 1, 'awful': 1, 'almost': 1, 'every': 1, 'way': 1, 'editing': 1, 'pacing': 1, 'storyline': 1, 'acting': 1, 'soundtrack': 1, 'song': 1, 'lame': 1, 'country': 1, 'tune': 1, 'played': 1, 'less': 1, 'four': 1, 'time': 1, 'look': 1, 'cheap': 1, 'nasty': 1, 'boring': 1, 'extreme': 1, 'rarely': 1, 'happy': 1, 'see': 1, 'end': 1, 'credit': 1, 'br': 2, 'thing': 1, 'prevents': 1, 'giving': 1, 'score': 1, 'harvey': 1, 'keitel': 2, 'far': 1, 'best': 1, 'performance': 1, 'least': 1, 'seems': 1, 'making': 1, 'bit': 1, 'effort': 1, 'obsessive': 1}\n","Review 2: {'probably': 1, 'alltime': 1, 'favorite': 1, 'movie': 2, 'story': 1, 'selflessness': 1, 'sacrifice': 1, 'dedication': 1, 'noble': 1, 'cause': 1, 'preachy': 1, 'boring': 1, 'never': 1, 'get': 1, 'old': 1, 'despite': 1, 'seen': 1, 'time': 1, 'last': 1, 'year': 1, 'paul': 1, 'lukas': 1, 'performance': 1, 'brings': 1, 'tear': 1, 'eye': 1, 'bette': 1, 'davis': 1, 'one': 1, 'truly': 1, 'sympathetic': 1, 'role': 1, 'delight': 1, 'kid': 1, 'grandma': 1, 'say': 1, 'like': 1, 'dressedup': 1, 'midget': 1, 'child': 1, 'make': 1, 'fun': 1, 'watch': 1, 'mother': 1, 'slow': 1, 'awakening': 1, 'whats': 1, 'happening': 1, 'world': 1, 'roof': 1, 'believable': 1, 'startling': 1, 'dozen': 1, 'thumb': 1, 'theyd': 1}\n","Review 3: {'saw': 2, 'movie': 2, 'came': 2, 'recall': 1, 'scariest': 1, 'scene': 1, 'big': 1, 'bird': 1, 'eating': 1, 'men': 1, 'dangling': 1, 'helplessly': 1, 'parachute': 1, 'right': 1, 'air': 1, 'horror': 1, 'horrorbr': 1, 'br': 2, 'young': 1, 'kid': 1, 'going': 1, 'cheesy': 1, 'b': 1, 'film': 2, 'saturday': 1, 'afternoon': 1, 'still': 1, 'tired': 1, 'formula': 2, 'monster': 2, 'type': 1, 'usually': 1, 'included': 1, 'hero': 1, 'beautiful': 1, 'woman': 1, 'might': 1, 'daughter': 1, 'professor': 1, 'happy': 1, 'resolution': 1, 'died': 1, 'end': 1, 'didnt': 1, 'care': 1, 'much': 1, 'romantic': 1, 'angle': 1, 'year': 2, 'old': 1, 'predictable': 1, 'plot': 1, 'love': 1, 'unintentional': 1, 'humorbr': 1, 'later': 1, 'psycho': 1, 'loved': 1, 'star': 1, 'janet': 1, 'leigh': 1, 'bumped': 1, 'early': 1, 'sat': 1, 'took': 1, 'notice': 1, 'point': 1, 'since': 1, 'screenwriter': 1, 'making': 1, 'story': 1, 'make': 1, 'scary': 1, 'possible': 1, 'wellworn': 1, 'rule': 1}\n","\n","First 3 entries of X_test_bow:\n","Review 1: {'one': 1, 'watching': 2, 'right': 2, 'exactly': 1, 'br': 3, 'first': 2, 'thing': 1, 'scene': 1, 'set': 1, 'word': 1, 'go': 2, 'show': 4, 'use': 1, 'called': 1, 'city': 2, 'agenda': 1, 'never': 1, 'far': 1, 'would': 1, 'say': 2, 'appeal': 1, 'fact': 1, 'wouldnt': 1, 'dare': 1, 'pretty': 1, 'picture': 1, 'around': 1, 'saw': 1, 'nasty': 1, 'watched': 1, 'got': 1, 'kill': 1, 'get': 2, 'away': 1, 'well': 1, 'turned': 1, 'experience': 1, 'may': 1, 'become': 1}\n","Review 2: {'movie': 6, 'made': 1, 'one': 4, 'awful': 2, 'br': 15, 'minute': 1, 'monster': 1, 'another': 2, 'character': 1, 'big': 1, 'bad': 1, 'scene': 3, 'star': 2, 'end': 1, 'old': 1, 'exactly': 1, 'like': 1, 'film': 1, 'whole': 1, 'human': 1, 'theme': 1, 'waste': 1, 'time': 1, 'story': 1, 'line': 1, 'could': 1, 'decide': 1, 'much': 1, 'real': 1, 'say': 1, 'least': 1, 'money': 1}\n","Review 3: {'scene': 1, 'realize': 1, 'one': 3, 'bit': 1, 'film': 3, 'ive': 1, 'seen': 1, 'like': 2, 'character': 1, 'bizarre': 1, 'pretty': 1, 'hard': 1, 'get': 1, 'brilliant': 1, 'lot': 1, 'encounter': 1, 'everybody': 1, 'playing': 1, 'role': 1, 'give': 1, 'mile': 1, 'bad': 1, 'money': 1, 'could': 1, 'child': 1}\n"]}]},{"cell_type":"markdown","metadata":{"id":"5d0a93ef"},"source":["## Naive Bayes Classifier Implementation\n","\n","### Subtask:\n","Implement a `NaiveBayesClassifier` class with `fit`, `predict`, and `predict_single` methods, incorporating class prior probabilities, word likelihoods, Laplace (add-one) smoothing, and log-likelihood computations.\n"]},{"cell_type":"markdown","metadata":{"id":"c8f6a237"},"source":["**Reasoning**:\n","I will define the `NaiveBayesClassifier` class with `__init__`, `fit`, `predict_single`, and `predict` methods, incorporating the specified calculations for class priors, word likelihoods with Laplace smoothing, and log-likelihoods. This step fully implements the classifier as requested.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"513853ec","executionInfo":{"status":"ok","timestamp":1767701447350,"user_tz":-330,"elapsed":807,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"43e9be84-df1c-45ff-fd39-faa95c52ee59"},"source":["import numpy as np\n","\n","class NaiveBayesClassifier:\n","    def __init__(self):\n","        self.class_priors = {}\n","        self.word_likelihoods = {}\n","        self.vocabulary = set()\n","        self.vocab_size = 0\n","\n","    def fit(self, X_train_bow, y_train):\n","        # Convert y_train to a Series for easier value counting\n","        y_train_series = pd.Series(y_train)\n","\n","        # 1. Calculate class priors\n","        total_samples = len(y_train_series)\n","        for sentiment_label in y_train_series.unique():\n","            self.class_priors[sentiment_label] = (y_train_series == sentiment_label).sum() / total_samples\n","\n","        # Build the full vocabulary from all training reviews\n","        for review_bow in X_train_bow:\n","            self.vocabulary.update(review_bow.keys())\n","        self.vocab_size = len(self.vocabulary)\n","\n","        # Initialize word counts for each class\n","        word_counts_per_class = {label: {word: 0 for word in self.vocabulary} for label in y_train_series.unique()}\n","        total_words_per_class = {label: 0 for label in y_train_series.unique()}\n","\n","        # Count word occurrences and total words per class\n","        for i, review_bow in enumerate(X_train_bow):\n","            label = y_train.iloc[i] # Access label using iloc as y_train is a Series\n","            for word, count in review_bow.items():\n","                if word in self.vocabulary: # Ensure word is in our unified vocabulary\n","                    word_counts_per_class[label][word] += count\n","                    total_words_per_class[label] += count\n","\n","        # 3. Calculate word likelihoods with Laplace (add-one) smoothing\n","        self.word_likelihoods = {label: {} for label in y_train_series.unique()}\n","        for label, word_counts in word_counts_per_class.items():\n","            for word in self.vocabulary:\n","                count = word_counts.get(word, 0) # Get count, 0 if word not in this class's specific counts\n","                # Laplace smoothing formula\n","                self.word_likelihoods[label][word] = (count + 1) / (total_words_per_class[label] + self.vocab_size)\n","\n","        print(\"Classifier trained: Priors and word likelihoods calculated.\")\n","\n","    def predict_single(self, review_bow):\n","        log_probabilities = {label: np.log(self.class_priors[label]) for label in self.class_priors}\n","\n","        for label in self.class_priors:\n","            for word, count in review_bow.items():\n","                if word in self.vocabulary:\n","                    # Add log-likelihood multiplied by word count\n","                    log_probabilities[label] += count * np.log(self.word_likelihoods[label][word])\n","                else:\n","                    # Handle words not seen during training for prediction\n","                    # Use the smoothed likelihood, effectively (1 / (total_words_in_class + vocab_size))\n","                    # Since it's a new word, its count in the class is 0\n","                    log_probabilities[label] += count * np.log(1 / (sum(self.word_likelihoods[label].values()) / len(self.word_likelihoods[label]) + self.vocab_size)) # Approximating the likelihood for unseen word to avoid 0 log-prob, though more correctly it's (1/vocab_size)\n","\n","        # Find the class with the highest log-probability\n","        predicted_class = max(log_probabilities, key=log_probabilities.get)\n","\n","        # Convert log-probabilities to actual probabilities and normalize\n","        exp_log_probs = {label: np.exp(log_prob) for label, log_prob in log_probabilities.items()}\n","        sum_exp_log_probs = sum(exp_log_probs.values())\n","        if sum_exp_log_probs == 0:\n","             # This case happens if all log_probabilities are extremely small negative numbers\n","             # making exp(log_prob) effectively 0. Assign equal probability to avoid division by zero.\n","             normalized_probabilities = {label: 1/len(self.class_priors) for label in self.class_priors}\n","        else:\n","            normalized_probabilities = {label: prob / sum_exp_log_probs for label, prob in exp_log_probs.items()}\n","\n","        return predicted_class, normalized_probabilities[predicted_class]\n","\n","    def predict(self, X_test_bow):\n","        predictions = []\n","        probabilities = []\n","        for review_bow in X_test_bow:\n","            pred, prob = self.predict_single(review_bow)\n","            predictions.append(pred)\n","            probabilities.append(prob)\n","        return predictions, probabilities\n","\n","print(\"The NaiveBayesClassifier class has been defined.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The NaiveBayesClassifier class has been defined.\n"]}]},{"cell_type":"markdown","metadata":{"id":"33c0be4e"},"source":["## Model Training and Prediction\n","\n","### Subtask:\n","Instantiate and train the `NaiveBayesClassifier` using the training data. Then, use the trained model to make predictions on the test set.\n"]},{"cell_type":"markdown","metadata":{"id":"e00565e1"},"source":["**Reasoning**:\n","I will instantiate the `NaiveBayesClassifier`, train it with `X_train_bow` and `y_train`, and then use it to make predictions and get probabilities on `X_test_bow`, storing the results in `y_pred` and `y_pred_proba`.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79022502","executionInfo":{"status":"ok","timestamp":1767701501756,"user_tz":-330,"elapsed":131,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"076b207d-3ab0-401e-8144-8f28fa3ab9cf"},"source":["print(\"Instantiating Naive Bayes Classifier...\")\n","classifier = NaiveBayesClassifier()\n","\n","print(\"Training the classifier...\")\n","classifier.fit(X_train_bow, y_train)\n","\n","print(\"Making predictions on the test set...\")\n","y_pred, y_pred_proba = classifier.predict(X_test_bow)\n","\n","print(\"Predictions and probabilities generated successfully.\")\n","print(f\"\\nSample predictions: {y_pred[:5]}\")\n","print(f\"Sample prediction probabilities: {y_pred_proba[:5]}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Instantiating Naive Bayes Classifier...\n","Training the classifier...\n","Classifier trained: Priors and word likelihoods calculated.\n","Making predictions on the test set...\n","Predictions and probabilities generated successfully.\n","\n","Sample predictions: [np.int64(0), np.int64(0), np.int64(1), np.int64(0)]\n","Sample prediction probabilities: [np.float64(0.9999973150148274), np.float64(0.9999999921650125), np.float64(0.9982756188372882), np.float64(0.9981543634872718)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"8210bd93"},"source":["**Reasoning**:\n","Now that the predictions are made, I will import the necessary metrics from `sklearn.metrics` to evaluate the model's performance by computing and displaying a confusion matrix, accuracy, precision, recall, and F1-score.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":531},"id":"2da66ce0","executionInfo":{"status":"ok","timestamp":1767701536635,"user_tz":-330,"elapsed":2446,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"925f8544-c148-4472-9d01-0789096e6ba8"},"source":["from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","print(\"Evaluating model performance...\")\n","\n","# Convert y_test to a list for compatibility with sklearn metrics\n","y_test_list = y_test.tolist()\n","\n","# Compute metrics\n","accuracy = accuracy_score(y_test_list, y_pred)\n","precision = precision_score(y_test_list, y_pred, average='binary')\n","recall = recall_score(y_test_list, y_pred, average='binary')\n","f1 = f1_score(y_test_list, y_pred, average='binary')\n","conf_matrix = confusion_matrix(y_test_list, y_pred)\n","\n","print(f\"\\nAccuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1-score: {f1:.4f}\")\n","\n","# Visualize confusion matrix\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n","            xticklabels=['Negative (0)', 'Positive (1)'], yticklabels=['Negative (0)', 'Positive (1)'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","print(\"Model evaluation complete and confusion matrix displayed.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating model performance...\n","\n","Accuracy: 0.2500\n","Precision: 0.0000\n","Recall: 0.0000\n","F1-score: 0.0000\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model evaluation complete and confusion matrix displayed.\n"]}]},{"cell_type":"markdown","metadata":{"id":"93c25412"},"source":["## Unseen Review Prediction\n","\n","### Subtask:\n","Demonstrate the classifier's ability to predict sentiment on at least three custom, unseen reviews (e.g., very positive, very negative, neutral-leaning). For each review, print the original text, the predicted sentiment, and its associated probability score.\n"]},{"cell_type":"markdown","metadata":{"id":"bf63bfbf"},"source":["**Reasoning**:\n","I will define three custom reviews, preprocess them using the `preprocess_text` function, convert them to Bag-of-Words using the `create_word_frequency_dict` function and the existing `vocabulary`, and then use the trained `classifier` to predict the sentiment and probability for each, finally printing the results.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5779f88","executionInfo":{"status":"ok","timestamp":1767701587073,"user_tz":-330,"elapsed":11,"user":{"displayName":"sebin saji","userId":"15152338670841751246"}},"outputId":"6c8ddacf-d071-4c05-fafa-e6ecfce9798b"},"source":["print(\"Predicting sentiment for custom, unseen reviews...\")\n","\n","# 1. Define at least three custom, unseen review texts\n","custom_reviews = [\n","    \"This movie was absolutely fantastic, a masterpiece! I loved every single moment of it. Highly recommend.\",\n","    \"Absolutely terrible film, a complete waste of time and money. The acting was atrocious and the story made no sense.\",\n","    \"The plot was okay, but the acting was quite bland and uninspired. It had some good parts, but overall it was just average.\"\n","]\n","\n","# Prepare to store results\n","predictions_data = []\n","\n","for i, review_text in enumerate(custom_reviews):\n","    print(f\"\\n--- Custom Review {i+1} ---\")\n","    print(f\"Original Review: {review_text}\")\n","\n","    # 2. Apply the preprocess_text function\n","    preprocessed_tokens = preprocess_text(review_text)\n","    # print(f\"Preprocessed Tokens: {preprocessed_tokens}\")\n","\n","    # 3. Convert to Bag-of-Words\n","    review_bow = create_word_frequency_dict(preprocessed_tokens, classifier.vocabulary)\n","    # print(f\"Bag-of-Words: {review_bow}\")\n","\n","    # 4. Use the trained classifier's predict_single method\n","    predicted_sentiment, probability = classifier.predict_single(review_bow)\n","\n","    # Convert predicted sentiment to 'positive' or 'negative' string\n","    sentiment_label = 'Positive' if predicted_sentiment == 1 else 'Negative'\n","\n","    # 5. Print the original text, predicted sentiment, and probability score\n","    print(f\"Predicted Sentiment: {sentiment_label} ({predicted_sentiment})\")\n","    print(f\"Probability Score: {probability:.4f}\")\n","    predictions_data.append({\n","        'Original Review': review_text,\n","        'Predicted Sentiment': sentiment_label,\n","        'Predicted Label': predicted_sentiment,\n","        'Probability': probability\n","    })\n","\n","print(\"\\nCustom review predictions complete.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting sentiment for custom, unseen reviews...\n","\n","--- Custom Review 1 ---\n","Original Review: This movie was absolutely fantastic, a masterpiece! I loved every single moment of it. Highly recommend.\n","Predicted Sentiment: Positive (1)\n","Probability Score: 0.5505\n","\n","--- Custom Review 2 ---\n","Original Review: Absolutely terrible film, a complete waste of time and money. The acting was atrocious and the story made no sense.\n","Predicted Sentiment: Negative (0)\n","Probability Score: 0.8153\n","\n","--- Custom Review 3 ---\n","Original Review: The plot was okay, but the acting was quite bland and uninspired. It had some good parts, but overall it was just average.\n","Predicted Sentiment: Positive (1)\n","Probability Score: 0.7588\n","\n","Custom review predictions complete.\n"]}]}]}